{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77edb72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b276f54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "# From Spacy Basics:\n",
    "doc = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edc85b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u'\"In the comming hours; the legendary manchester United will not be legendary anymore against Arsenal Fc HAHa\" -> Peter Drury')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d84b01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"In the comming hours the legendary manchester United will not be legendary anymore against Arsenal Fc HAHa\" -> Peter Drury\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in doc2.sents:\n",
    "    print(sent)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9de509",
   "metadata": {},
   "source": [
    "# Adding a new rule to the Pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4d75782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'set_custom_boundaries', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "from spacy.language import Language\n",
    "\n",
    "# ADD A NEW RULE TO THE PIPELINE\n",
    "@Language.component(\"set_custom_boundaries\")  # Assign a name to the custom component\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == ';':\n",
    "            doc[token.i].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")  # Add the custom component by its name\n",
    "\n",
    "print(nlp.pipe_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d8dc258",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'\"In the comming hours; the legendary manchester United will not be legendary anymore against Arsenal Fc HAHa\" -> Peter Drury')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c0157a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"In the comming hours\n",
      "; the legendary manchester United will not be legendary anymore against Arsenal Fc HAHa\" -> Peter Drury\n"
     ]
    }
   ],
   "source": [
    "for sent in doc3.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "645b1255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the segmentation rules ie to break on line breaks etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f87c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the spacy lib\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10d3e9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence. This is another.\n",
      "\n",
      "This is a \n",
      "third sentence.\n"
     ]
    }
   ],
   "source": [
    "mystring = u\"This is a sentence. This is another.\\n\\nThis is a \\nthird sentence.\"\n",
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed532374",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d65c8d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is another.\n",
      "\n",
      "\n",
      "This is a \n",
      "third sentence.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16815e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence. This is another.\n",
      "\n",
      "This is a \n",
      "third sentence.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"custom_sentencizer\")\n",
    "def custom_sentencizer(doc):\n",
    "    for i, token in enumerate(doc[:-2]):\n",
    "        # Define sentence start if pipe + titlecase token\n",
    "        if token.text == \"|\" and doc[i + 1].is_title:\n",
    "            doc[i + 1].is_sent_start = True\n",
    "        else:\n",
    "            # Explicitly set sentence start to False otherwise, to tell\n",
    "            # the parser to leave those tokens alone\n",
    "            doc[i + 1].is_sent_start = False\n",
    "    return doc\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"custom_sentencizer\", before=\"parser\")  # Insert before the parser\n",
    "doc = nlp(mystring)\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dd5d8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sentence', '.', 'This', 'is', 'another', '.', '\\n\\n', 'This', 'is', 'a', '\\n', 'third', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(mystring)\n",
    "for sent in doc.sents:\n",
    "    print([token.text for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b566354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
